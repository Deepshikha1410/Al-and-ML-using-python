{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFZRpLpK02pB"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deSnZmVy02pF"
   },
   "source": [
    "\n",
    "# Computer vision\n",
    "## Session 13b\n",
    "### Basic Operation CV2\n",
    "\n",
    "<img src='../../prasami_images/prasami_color_tutorials_small.png' width='400' alt=\"By Pramod Sharma : pramod.sharma@prasami.com\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt0pfyeA02pK"
   },
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__T9cczP02pL"
   },
   "outputs": [],
   "source": [
    "# Some basic parameters\n",
    "inpDir = '../../input'\n",
    "outDir = '../output'\n",
    "dataDir = 'basic_operations'\n",
    "\n",
    "RANDOM_STATE = 24\n",
    "\n",
    "np.random.seed(RANDOM_STATE) # Set Random Seed for reproducible  results\n",
    "\n",
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 12),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'\n",
    "         }\n",
    "\n",
    "CMAP = 'jet'\n",
    "\n",
    "LINE_THICK = 1\n",
    "\n",
    "MARK_COLOR = (15, 82, 186)\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_read_image(fileName):\n",
    "    '''\n",
    "    Args:\n",
    "        fileName : Path of image file to read\n",
    "    returns:\n",
    "        im: image in cv2 format\n",
    "        rgbIm: image in RGB format\n",
    "    \n",
    "    '''\n",
    "    imgPath = os.path.join(inpDir, dataDir, fileName)\n",
    "    \n",
    "    # Read image file\n",
    "    im = cv2.imread(imgPath, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    \n",
    "    if im is None:\n",
    "        print('Could not open or find the image:', fileName)\n",
    "        exit(0)\n",
    "    else:\n",
    "        # convert to RGB image\n",
    "        rgbIm = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "        return im, rgbIm\n",
    "\n",
    "    \n",
    "def fn_plot_one_img(im):\n",
    "    \n",
    "    '''\n",
    "    Args:\n",
    "        im : image to display and save\n",
    "    \n",
    "    '''\n",
    "    # showing image\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(outDir, imgFileName))\n",
    "        \n",
    "def fn_plot_images(im_lst):\n",
    "    '''\n",
    "    Args:\n",
    "        img_list: list of images\n",
    "    '''\n",
    "    nRows = 1\n",
    "    nCols = len(im_lst)\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nRows, nCols)\n",
    "    \n",
    "    for i in range(nCols):\n",
    "        axes[i].imshow(im_lst[i]['img'], cmap = im_lst[i]['cmap'])\n",
    "        axes[i].set_title(im_lst[i]['name'])\n",
    "\n",
    "        axes[i].set_xticklabels([]);\n",
    "        axes[i].set_yticklabels([]);\n",
    "\n",
    "                \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Contrast Images\n",
    "\n",
    "### Histogram Equalization\n",
    "\n",
    "Histogram $\\rightarrow$ how many pixel with each of value between 0 and 255.\n",
    "\n",
    "<img src='../../images/Histograms.png' width='600' alt=\"Histogram\" />\n",
    "\n",
    "\n",
    "Plotting Histogram of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bright image\n",
    "bFileName = '/home/hpcap/Desktop/modules/Ai/Data/input-20240618T113733Z-001/input/basic_operations/11.jpeg' #'DSC_2477.JPG'\n",
    "\n",
    "brightImg, brightRBG = fn_read_image(bFileName)\n",
    "\n",
    "# Resizing to reduce processing time\n",
    "#brightImg = cv2.resize(brightImg, ( 1024, 688))\n",
    "#brightRBG = cv2.resize(brightRBG, ( 1024, 688))\n",
    "\n",
    "\n",
    "# load dark image\n",
    "dFileName = '/home/hpcap/Desktop/modules/Ai/Data/input-20240618T113733Z-001/input/basic_operations/094.JPG'#'kids.jpeg'\n",
    "\n",
    "darkImg, darkRBG  = fn_read_image(dFileName)\n",
    "\n",
    "# Resizing to reduce processing time\n",
    "#darkImg = cv2.resize(darkImg, ( 1024, 688))\n",
    "#darkRBG = cv2.resize(darkRBG, ( 1024, 688))\n",
    "\n",
    "\n",
    "img_lst = [{'img': brightRBG, 'name': 'Bright Image','cmap' : CMAP},\n",
    "           {'img': darkRBG, 'name': 'Dark Image','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darkImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.hist(brightImg.flatten(), bins = 25, alpha = 0.7, \n",
    "         color = 'orange', ec = 'r')\n",
    "\n",
    "plt.hist(darkImg.flatten(), bins = 25, alpha = 0.7, \n",
    "         color = 'lightblue', \n",
    "         ec = 'b')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate histogram using cv2.calcHist()\n",
    "brightHist = cv2.calcHist([brightImg], [0], None, [256], [0,256])\n",
    "darkHist = cv2.calcHist([darkImg], [0], None, [256], [0,256])\n",
    "\n",
    "# Display the histogram\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(brightHist)\n",
    "plt.plot(darkHist)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 D histogram\n",
    "\n",
    "We have seen 1 D histograms so far. We need to use 2 D histograms, if we want to find correlation between two channels, say Blue and Green. Function is same. Some of the parameters are as follows:\n",
    "- Channels: [ 0, 1 ], [ 1, 2 ], [ 0, 2 ] for (Blue, Green),  (Green, Red) and (Blue, Red) respectively.\n",
    "- bins: for each channel separately, say [256, 256]\n",
    "- range: [0,256, 0, 256] for 8-bit image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert to HSV. In HSV mode 2 channels can represent color. \n",
    "brightHSV = cv2.cvtColor(brightImg, cv2.COLOR_BGR2HSV)\n",
    "darkHSV = cv2.cvtColor(darkImg, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# 2D histogram for Blue and Green channels.\n",
    "brightHist = cv2.calcHist([brightHSV], [0, 1], None, [100, 100], \n",
    "                          [0, 256, 0, 256])\n",
    "\n",
    "darkHist = cv2.calcHist([darkHSV], [0, 1], None, [100, 100], \n",
    "                        [0, 256, 0, 256])\n",
    "\n",
    "\n",
    "# show using matplotlib\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.imshow(brightHist, interpolation='nearest', cmap = 'gray')\n",
    "ax.set_xticklabels([]);\n",
    "ax.set_yticklabels([]);\n",
    "\n",
    "ax = axes[1]\n",
    "ax.imshow(darkHist, interpolation='nearest', cmap = 'gray')\n",
    "ax.set_xticklabels([]);\n",
    "ax.set_yticklabels([]);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Equalization\n",
    "Equalizes the histogram of a grayscale image.\n",
    "\n",
    "Parameters\n",
    "- src\tSource 8-bit single channel image.\n",
    "- dst\tDestination image of the same size and type as src .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalBlue = cv2.equalizeHist(darkImg[:, :, 0]) \n",
    "equalGreen = cv2.equalizeHist(darkImg[:, :, 1]) \n",
    "equalRed = cv2.equalizeHist(darkImg[:, :, 2]) \n",
    "\n",
    "equalRBG = np.zeros_like(darkImg)\n",
    "equalRBG[:, :, 0] = equalRed\n",
    "equalRBG[:, :, 1] = equalGreen\n",
    "equalRBG[:, :, 2] = equalBlue\n",
    "\n",
    "img_lst = [{'img': darkRBG, 'name': 'Original RGB','cmap' : CMAP},\n",
    "           {'img': equalRBG, 'name': 'Equalized','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)\n",
    "\n",
    "cv2.imwrite(os.path.join(outDir,'dark_image_equal.png'), \n",
    "            cv2.cvtColor(equalRBG, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Histogram Equalization\n",
    "\n",
    "What if image has significant dark portions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing to reduce processing time\n",
    "#darkImg = cv2.resize(darkImg, ( 1024, 688))\n",
    "\n",
    "#darkRBG = cv2.cvtColor(darkImg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "claheBlue = clahe.apply(darkImg[:,:, 0])\n",
    "claheGreen = clahe.apply(darkImg[:,:, 1])\n",
    "claheRed = clahe.apply(darkImg[:,:, 2])\n",
    "\n",
    "claheImg = np.zeros_like(darkImg)\n",
    "\n",
    "claheImg [ :, :, 0] = claheRed\n",
    "claheImg [ :, :, 1] = claheGreen\n",
    "claheImg [ :, :, 2] = claheBlue\n",
    "\n",
    " \n",
    "img_lst = [{'img': darkRBG, 'name': 'Original RGB','cmap' : CMAP},\n",
    "           {'img': claheImg, 'name': 'Equalized','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)\n",
    "\n",
    "\n",
    "cv2.imwrite(os.path.join(outDir,'dark_image_clahe.png'), cv2.cvtColor(claheImg, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolations\n",
    "\n",
    "A number of interpolation techniques are available as shown below:\n",
    "<img src='../../images/Interpolation.png' width='600' alt=\"Interpolation Techniques\" />\n",
    "\n",
    "Non-adoptive perform interpolation in a fixed pattern for every pixel, while adoptive algorithms detect local spacial features, such as edges, of the pixel neighborhood and make effective choices.\n",
    "\n",
    "### Nearest Neighbor Interpolation\n",
    "\n",
    "$$\\begin{bmatrix} 10 & 20 \\\\ 30 & 40\\end{bmatrix}\\stackrel{2 x}{\\rightarrow}\\begin{bmatrix} 10 & 10 & 20 & 20 \\\\10 & 10 & 20 & 20 \\\\ 30 & 30 & 40 & 40\\\\ 30 & 30 & 40 & 40\\end{bmatrix}$$\n",
    "\n",
    "### Bi-linear Interpolation\n",
    "\n",
    "Linear interpolation in both the directions.\n",
    "\n",
    "- Fix corner pixel as per the original image and then interpolate all intermediate values.\n",
    "\n",
    "$$\\begin{bmatrix} 10 & 20 \\\\ 30 & 40\\end{bmatrix}\\stackrel{2 x}{\\rightarrow}\\begin{bmatrix} 10 & 12 & 17 & 20 \\\\15 & 17 & 22 & 25 \\\\ 25 & 27 & 32 & 35\\\\ 30 & 32 & 37 & 40\\end{bmatrix}$$\n",
    "\n",
    "- This  performs better than nearst neighbor but at sharp edges, this algorithm is not ideal.\n",
    "\n",
    "### Bi-cubic Interpolation\n",
    "- Bi-linear uses 4 nearest neighbors to get the output while Bi-cubic uses 16 (4 x 4) neighbors.\n",
    "- Weight distribution too is little different\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "fx & = ( dx + 0.5 ) * scale_x - 0.5\\\\\n",
    "sx & = cvFloor(fx)\\\\\n",
    "fx & -= sx\\\\\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "**Note:** cvFloor roundoff to lower int\n",
    "\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "A & = -0.75f\\\\\n",
    "coeffs[0] & = ((A*(x + 1) - 5*A)*(x + 1) + 8*A)*(x + 1) - 4*A\\\\\n",
    "coeffs[1] & = ((A + 2)*x - (A + 3))*x*x + 1\\\\\n",
    "coeffs[2] & = ((A + 2)*(1 - x) - (A + 3))*(1 - x)*(1 - x) + 1\\\\\n",
    "coeffs[3] & = 1.f - coeffs[0] - coeffs[1] - coeffs[2]\\\\\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "$$\\begin{bmatrix} 10 & 20 \\\\ 30 & 40\\end{bmatrix}\\stackrel{2 x}{\\rightarrow}\\begin{bmatrix} 7 & 10 & 16 & 19 \\\\13 & 17 & 22 & 26 \\\\ 24 & 28 & 33 & 37\\\\ 31 & 34 & 40 & 43\\end{bmatrix}$$\n",
    "\n",
    "* Notably sharper image than previous two and balances processing time and output quality. Hence, widely used. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bright image\n",
    "imgFileName = '/home/hpcap/Desktop/modules/Ai/Data/input-20240618T113733Z-001/input/basic_operations/car_2_small.png'\n",
    "oFileName = '/home/hpcap/Desktop/modules/Ai/Data/input-20240618T113733Z-001/input/basic_operations/car_2_cropped.png'\n",
    "\n",
    "srcImg, rgbImg = fn_read_image(imgFileName)\n",
    "oImg, oRgbImg  = fn_read_image(oFileName)\n",
    "\n",
    "img_lst = [{'img': oImg, 'name': 'Original Image','cmap' : CMAP},\n",
    "           {'img': oRgbImg, 'name': 'Original RGB Image','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)\n",
    "\n",
    "img_lst = [{'img': srcImg, 'name': 'Reduced Source Image','cmap' : CMAP},\n",
    "           {'img': rgbImg, 'name': 'Reduced rgb Image','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearImg = cv2.resize(rgbImg, None, fx = 10, fy = 10, \n",
    "                     interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "img_lst = [{'img': rgbImg, 'name': 'rgb Image','cmap' : CMAP},\n",
    "           {'img': nearImg, 'name': 'Nearest Neighbor','cmap' : CMAP}]\n",
    "print ('Shape of source', rgbImg.shape, 'Shape of destination', nearImg.shape)\n",
    "fn_plot_images(img_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces a pixlated image, no new data!\n",
    "\n",
    "## Bi-Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bLinImg = cv2.resize(rgbImg, None, fx = 10, fy = 10, \n",
    "                     interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "img_lst = [{'img': rgbImg, 'name': 'rgb Image','cmap' : CMAP},\n",
    "           {'img': bLinImg, 'name': 'Bi-Linear','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks smooth, but edges are blurred!\n",
    "\n",
    "### Bi-Cubic Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bCubImg = cv2.resize(rgbImg, None, fx = 10, fy = 10,\n",
    "                     interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "img_lst = [{'img': rgbImg, 'name': 'rgb Image','cmap' : CMAP},\n",
    "           {'img': bCubImg, 'name': 'Bi-Cubic','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lst = [oRgbImg, nearImg,bLinImg, bCubImg]\n",
    "\n",
    "\n",
    "stackedImg = np.hstack(img_lst)\n",
    "\n",
    "# Display the images\n",
    "fn_plot_one_img(stackedImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB Track Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    '''\n",
    "     Do nothing ! Good!\n",
    "    '''\n",
    "    pass\n",
    " \n",
    "# Create a black image, a window\n",
    "blankImg = np.zeros((512,512,3), np.uint8)\n",
    "\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('Red','image',0,255,nothing)\n",
    "cv2.createTrackbar('Green','image',0,255,nothing)\n",
    "cv2.createTrackbar('Blue','image',0,255,nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    cv2.imshow('image',blankImg)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    # get current positions of three trackbars\n",
    "    r = cv2.getTrackbarPos('Red','image')\n",
    "    g = cv2.getTrackbarPos('Green','image')\n",
    "    b = cv2.getTrackbarPos('Blue','image')\n",
    "    \n",
    "    print (r, b, g)\n",
    "    \n",
    "    blankImg[:] = [b,g,r]\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image, a window\n",
    "blankImg = np.zeros((512,512,3), np.uint8)\n",
    "cv2.namedWindow('TrackerBars',cv2.WINDOW_NORMAL)\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('H','TrackerBars',0,180,nothing)\n",
    "cv2.createTrackbar('S','TrackerBars',0,255,nothing)\n",
    "cv2.createTrackbar('I','TrackerBars',0,255,nothing)\n",
    "\n",
    "while(True):\n",
    "    cv2.imshow('image',blankImg)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    # get current positions of four trackbars\n",
    "    h = cv2.getTrackbarPos('H','TrackerBars')\n",
    "    s = cv2.getTrackbarPos('S','TrackerBars')\n",
    "    v = cv2.getTrackbarPos('I','TrackerBars')\n",
    "    \n",
    "    blankImg[:,:] = [h,s,v]\n",
    "    blankImg = cv2.cvtColor(blankImg, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original image\n",
    "imgFileName = '/home/hpcap/Desktop/modules/Ai/Data/input-20240618T113733Z-001/input/basic_operations/094.JPG'\n",
    "\n",
    "srcImg, rgbImg = fn_read_image(imgFileName)\n",
    "\n",
    "# Resizing to fit terminal\n",
    "srcImg = cv2.resize(srcImg, ( 1280, 960))\n",
    "\n",
    "# Create list to store noisy images\n",
    "images = []\n",
    "\n",
    "# Generate noisy images using cv2.randn. Can use your own mean and std.\n",
    "for _ in range(20):\n",
    "    \n",
    "    img1 = srcImg.copy() \n",
    "    \n",
    "    cv2.randn(img1,(0,0,0),(50,50,50))\n",
    "    \n",
    "    images.append ( srcImg + img1 )\n",
    "\n",
    "    \n",
    "# For averaging create an empty array, then add images to this array.\n",
    "\n",
    "avgImg = np.zeros((srcImg.shape[0],\n",
    "                   srcImg.shape[1],\n",
    "                   srcImg.shape[2]), np.float32)\n",
    "\n",
    "for im in images:\n",
    "    \n",
    "    avgImg = avgImg + im / 20\n",
    "\n",
    "\n",
    "# Round the float values. Always specify the dtype\n",
    "\n",
    "avgImg = np.array ( np.round ( avgImg ), dtype=np.uint8 )\n",
    "\n",
    "rgbImg = cv2.cvtColor(srcImg, cv2.COLOR_BGR2RGB)\n",
    "avgImg = cv2.cvtColor(avgImg, cv2.COLOR_BGR2RGB)\n",
    "noisyImg = cv2.cvtColor(images[0], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the images\n",
    "img_lst = [{'img': rgbImg, 'name': 'Original Image','cmap' : CMAP},\n",
    "           {'img': noisyImg, 'name': 'Noisy','cmap' : CMAP},\n",
    "           {'img': avgImg, 'name': 'Averaged Image','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_plot_one_img(avgImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity Transformation\n",
    "\n",
    "Basic types of transformation functions used for image enhancement are:\n",
    "- Linear (Negative and Identity Transformations)\n",
    "- Log and inverse-log transformations\n",
    "- Power Law transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original image\n",
    "imgFileName = '/home/hpcap/Pictures/trial.jpeg'\n",
    "\n",
    "srcImg, rgbImg = fn_read_image(imgFileName)\n",
    "\n",
    "# Create Negative image\n",
    "negImg = cv2.bitwise_not(srcImg)\n",
    "\n",
    "#rgbImg = cv2.cvtColor(srcImg, cv2.COLOR_BGR2RGB)\n",
    "negImg = cv2.cvtColor(negImg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the images\n",
    "img_lst = [{'img': rgbImg, 'name': 'Original Image','cmap' : CMAP},\n",
    "           {'img': negImg, 'name': 'Negative','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation method\n",
    "c = 255 / np.log1p(1+np.max(srcImg))\n",
    "\n",
    "\n",
    "logImg = np.array((c * (np.log1p(1+srcImg))), dtype = 'uint8')\n",
    "\n",
    "rgbImg = cv2.cvtColor(srcImg, cv2.COLOR_BGR2RGB)\n",
    "logImg = cv2.cvtColor(logImg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the images\n",
    "img_lst = [{'img': rgbImg, 'name': 'Original Image','cmap' : CMAP},\n",
    "           {'img': logImg, 'name': 'Log Transformation','cmap' : CMAP}]\n",
    "\n",
    "fn_plot_images(img_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = []\n",
    "\n",
    "# Trying 4 gamma values.\n",
    "for gamma in [0.1, 0.5, 1.2, 2.2]:\n",
    "      \n",
    "    # Apply gamma correction.\n",
    "    gamma_corrected = np.array(255*(srcImg / 255) ** gamma, \n",
    "                               dtype = 'uint8')\n",
    "  \n",
    "    # create gamma file name\n",
    "    gmaFileName = os.path.join(outDir, \n",
    "                               f'{imgFileName}_gamma_{gamma}.jpg')\n",
    "    \n",
    "    # Save edited images.\n",
    "    cv2.imwrite(gmaFileName,\n",
    "                gamma_corrected)\n",
    "    \n",
    "    file_list.append(gmaFileName)\n",
    "    \n",
    "img_list = []\n",
    "\n",
    "for f in  file_list:\n",
    "    \n",
    "    gImg = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    gImg = cv2.cvtColor(gImg, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img_list.append(gImg)\n",
    "\n",
    "gammaImg = np.hstack(img_list)\n",
    "\n",
    "# Display the images\n",
    "fn_plot_one_img(gammaImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original image\n",
    "imgFileName = '/home/hpcap/Desktop/modules/Ai/Data/input-20240618T113733Z-001/input/basic_operations/bright_image.jpeg'\n",
    "\n",
    "def fn_empty(a):\n",
    "    pass\n",
    "\n",
    "# Create a window\n",
    "cv2.namedWindow('TrackerBars',cv2.WINDOW_NORMAL)\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('Hue Min', 'TrackerBars',   0, 179, fn_empty)\n",
    "cv2.createTrackbar('Hue Max', 'TrackerBars',  19, 179, fn_empty)\n",
    "cv2.createTrackbar('Sat Min', 'TrackerBars', 110, 255, fn_empty)\n",
    "cv2.createTrackbar('Sat Max', 'TrackerBars', 240, 255, fn_empty)\n",
    "cv2.createTrackbar('Val Min', 'TrackerBars', 153, 255, fn_empty)\n",
    "cv2.createTrackbar('Val Max', 'TrackerBars', 250, 255, fn_empty)\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    srcImg, rgbImg = fn_read_image(imgFileName)\n",
    "    #srcImg = cv2.resize(srcImg, ( 960, 1280))\n",
    "    \n",
    "    hsvImg = cv2.cvtColor(srcImg, cv2.COLOR_BGR2HSV)\n",
    "                \n",
    "    # get current positions of four trackbars\n",
    "    h_min = cv2.getTrackbarPos('Hue Min','TrackerBars')\n",
    "    h_max = cv2.getTrackbarPos('Hue Max','TrackerBars')\n",
    "    s_min = cv2.getTrackbarPos('Sat Min','TrackerBars')\n",
    "    s_max = cv2.getTrackbarPos('Sat Max','TrackerBars')\n",
    "    v_min = cv2.getTrackbarPos('Val Min','TrackerBars')\n",
    "    v_max = cv2.getTrackbarPos('Val Max','TrackerBars')\n",
    "     \n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    \n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    \n",
    "    maskImg = cv2.inRange(hsvImg, lower, upper)\n",
    "\n",
    "    cv2.imshow('Original',srcImg)\n",
    "    cv2.imshow('HSV',hsvImg)\n",
    "    cv2.imshow('Mask',maskImg)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "S05a_one_hidden_layer_with_tanh_wip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
